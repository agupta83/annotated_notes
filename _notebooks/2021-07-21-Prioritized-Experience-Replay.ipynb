{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Prioritized Experience Replay.ipynb","provenance":[],"collapsed_sections":["4rolw0rmF8M4"],"toc_visible":true,"authorship_tag":"ABX9TyOGrqco0fwk/vV95YNzMQpf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prioritized Experience Replay\n","\n","- toc: true \n","- badges: true\n","- comments: true\n","- categories: [RL]"],"metadata":{"id":"4rolw0rmF8M4"}},{"cell_type":"markdown","source":["# Experience Replay\n","\n","* Online Reinforcement Learning (RL) agents update their parameter as they make observation.\n","* Two Issues:\n","  * Strongly correlated updates (breaks i.i.d assumption of stochastic optimizers)\n","  * Rare events are immediately discarded\n","* _Experience Replay_ (*ER*) {% cite er %} stores the observation in a replay memory\n","  * Can mix recent and non-recent observations (no temporal correlation)\n","  * Rare event can be re-used\n","* ER reduce amount of observations required to learn and replace with computational and memory resources (cheaper)\n","\n","\n","# Prioritized ER\n","The intuition behind prioritized experience replay {% cite per %} is\n","* Some transitions are more informative than other\n","  * Transitions may be more or less surprising, redundant or task relevant\n","  * Some transition may not be immediately useful (RL agent not mature enough)\n","* Replay _important transitions_ more frequently and therefore learn more efficiently.\n","\n","## Temporal Difference as proxy measurement\n","* The magnitude of temporal difference (TD) error $\\delta$ measures how far the value is from next-step bootstrap estimate {% cite Andre98generalizedprioritized %}.\n","* Reasonable proxy as it indicates how \"surprising\" the transition is.\n","\n","> Warning: Ignores inherent stochasticity in reward and transitions (poor TD estimates).\n","> Warning: Limitation from partial observability (unlearnable transitions)\n","\n","\n","## Greedy TD-error prioritization\n","\n","* Algorithm\n","  * Stores last TD error of a transtion in replay buffer\n","  * Transition with largest abs. TD error get replayed. Q-learning update $\\propto$ TD-error\n","  * New transition gets highest priority\n","* Substantial reduction in training effort\n","* Implementation: Binary heap for priority queue\n","  * Sampling: $O(1)$\n","  * Update: $O(log N)$\n","\n","### Issues\n","* To avoid expensive sweep over entire replay memory, only replayed transition is updated\n","  > Warning: Transition with low TD-error in first visit may not be replayed for a while.\n","\n","* Sensitive to noise (stochastic reward, bootstrapping noise)\n","* Prone to over-fitting as high error transitions get replayed frequently (lack diversity)\n","\n","---"],"metadata":{"id":"WwiWC2EmPpYi"}},{"cell_type":"markdown","source":["# Stochastic Prioritization\n","\n","* Interpolates between greedy and uniform random sampling\n","* Probability of sampling transition $i$ is given by \n","\n","\n","$$\n","P(i) = \\frac{p_i^\\alpha}{\\sum_k p_k^\\alpha}\n","$$\n","\n","* where,\n","  * $p_i$ is the **priority of transition**\n","  * hyperparameter $\\alpha$ determines how much prioritization to use (uniform sampling with $\\alpha = 0$)\n","* monotonic in transition priority\n","\n","## Variants\n","  * *Proportional prioritization*: $p_i = |\\delta_i| + \\epsilon$\n","  * *Rank based prioritization*: $p_i = \\frac{1}{rank(i)}$ where $rank(i)$ is rank of transition if sorted $|\\delta_i|$\n","    * insensitive to outlier and hence more robust\n","\n","## Bias\n","* Stochastic updates relies on the update being from same distribution as its expectation\n","* Prioritized replay induce bias as it chages the update distribution\n","* bias correction using importance sampling weights\n","$$w_i = \\bigg(\\frac{1}{N} \\frac{1}{P(i)}\\bigg)^\\beta$$ \n","* where, \n","  * hyper parameter $\\beta$ fully compensates for non-uniform $P(i)$ when $\\beta = 1$.\n","  * Normalize weights by $\\frac{1}{\\max_i w_i}$ for stability. \n","  * this is applied to Q-learning by $w_i\\delta_i$ (weighted IS)\n","* Unbiased nature is most important towards the convergence at end of training.\n","> Note: Process is highly non-stationary (changing policy, state dist. and bootstrapped targets)\n","* Anneal the amount of correction over time.\n","* prioritization ensures high-error transitions are seen many times while IS correction reduces gradient magnitude.\n","\n","---"],"metadata":{"id":"1k6GieidtlBc"}},{"cell_type":"markdown","source":["# Implementation\n","\n","## Rank based prioritization\n","\n","* Approximate $cdf$ with piecewise linear function with $k$ equal size segments\n","* First, sample a segment and then sample uniformly within among transitions within segment\n","* for minibatch based learning:\n","  * choose $k$ to be size of minibatch\n","  * sample one transition from each segment\n","\n","## Propotional prioritization\n","\n","* Use sum tree"],"metadata":{"id":"ErF3yLEyW6W_"}},{"cell_type":"markdown","source":["\n","### Binary Segment Tree\n","\n","* Efficiently calculate $\\sum_k^i p_k^\\alpha$, the cumulative probability,\n","which is needed to sample.\n","* To find $\\min p_i^\\alpha$, which is needed for $\\frac{1}{\\max_i w_i}$.\n","> Note: We can also use a min-heap for this.\n","Binary Segment Tree lets us calculate these in $\\mathcal{O}(\\log n)$\n","time, which is way more efficient that the naive $\\mathcal{O}(n)$\n","approach.\n","\n","A Binary Segment Tree is a data structure that allows answering range queries \n","over an array effectively, while still being flexible enough to allow modifying the array.\n","\n","This is how a binary segment tree works for sum (it is similar for minimum)\n","* Let $x_i$ where $i \\in \\{1, 2 \\cdots, N\\}$ be the list of $N$ values we want to represent.\n","* Let $b_{h,j}$ be the $j^{\\mathop{th}}$ node at height $h^{\\mathop{th}}$ in the binary tree.\n","* The two children of node $b_{h,j}$ are $b_{h+1,2j}$ and $b_{h+1,2j + 1}$.\n","* The leaf nodes are at height $H = \\left\\lceil {1 + \\log_2 N} \\right\\rceil$ will have values of $x$.\n","\n","Every node keeps the sum of the two child nodes. That is, the root node keeps the sum of the entire \n","array of values. The left and right children of the root node keep the sum of the first half of the \n","array andthe sum of the second half of the array, respectively. and so on\n","\n","$$b_{h,j} = \\sum_{k = (j -1) * 2^{H - h} + 1}^{j * 2^{H - h}} x_k$$\n","Number of nodes at height $h$,\n","$$N_h = \\left\\lceil{\\frac{N}{H - h + 1}} \\right\\rceil$$\n","This is equal to the sum of nodes in all levels above $h$.\n","So we can use a single array $a$ to store the tree, where,\n","$$b_{h,j} \\rightarrow a_{N_h + j}$$\n","\n","Then child nodes of $a_i$ are $a_{2i}$ and $a_{2i + 1}$.\n","That is,\n","$$a_i = a_{2i} + a_{2i + 1}$$\n","\n","This way of maintaining binary trees is very easy to program.\n",">Note: indexing starting from 1.\n",">Note: We use the same structure to compute the minimum."],"metadata":{"id":"sIDqU7v53xCD"}},{"cell_type":"code","execution_count":null,"source":["import random\n","\n","import numpy as np\n","from typing import List\n","from dataclasses import dataclass\n","\n","@dataclass\n","class Transition():\n","    current_state = np.zeros(shape=(1, 10), dtype=np.float)\n","    action = 0\n","    reward = 0.0\n","    next_state = np.zeros(shape=(1, 10), dtype=np.float)\n","    done = 0\n","\n","\n","class PriorityExperienceReplayBuffer:\n","    def __init__(self, capacity, alpha):\n","        \"\"\"\n","        ### Initialize\n","        \"\"\"\n","        # We use a power of $2$ for capacity because it simplifies the code and debugging\n","        self.capacity = capacity\n","        # $\\alpha$\n","        self.alpha = alpha\n","\n","        # Maintain segment binary trees to take sum and find minimum over a range\n","        self.priority_sum = [0 for _ in range(2 * self.capacity)]\n","        self.priority_min = [float('inf') for _ in range(2 * self.capacity)]\n","\n","        # Current max priority, $p$, to be assigned to new transitions\n","        self.max_priority = 1.\n","\n","        # Arrays for buffer\n","        self.data = [Transition() for _ in range(capacity)]\n","        # We use cyclic buffers to store data, and `next_idx` keeps the index of the next empty\n","        # slot\n","        self.next_idx = 0\n","\n","        # Size of the buffer\n","        self.size = 0\n","\n","    def add(self, transition: Transition):\n","        \"\"\"\n","        ### Add sample to queue\n","        \"\"\"\n","\n","        # Get next available slot\n","        idx = self.next_idx\n","\n","        # store in the queue\n","        self.data[idx] = transition\n","\n","        # Increment next available slot\n","        self.next_idx = (idx + 1) % self.capacity\n","        # Calculate the size\n","        self.size = min(self.capacity, self.size + 1)\n","\n","        # $p_i^\\alpha$, new samples get `max_priority`\n","        priority_alpha = self.max_priority ** self.alpha\n","        # Update the two segment trees for sum and minimum\n","        self._set_priority_min(idx, priority_alpha)\n","        self._set_priority_sum(idx, priority_alpha)\n","\n","    def _set_priority_min(self, idx, priority_alpha):\n","        \"\"\"\n","        #### Set priority in binary segment tree for minimum\n","        \"\"\"\n","\n","        # Leaf of the binary tree\n","        idx += self.capacity\n","        self.priority_min[idx] = priority_alpha\n","\n","        # Update tree, by traversing along ancestors.\n","        # Continue until the root of the tree.\n","        while idx >= 2:\n","            # Get the index of the parent node\n","            idx //= 2\n","            # Value of the parent node is the minimum of it's two children\n","            self.priority_min[idx] = min(self.priority_min[2 * idx], self.priority_min[2 * idx + 1])\n","\n","    def _set_priority_sum(self, idx, priority):\n","        \"\"\"\n","        #### Set priority in binary segment tree for sum\n","        \"\"\"\n","\n","        # Leaf of the binary tree\n","        idx += self.capacity\n","        # Set the priority at the leaf\n","        self.priority_sum[idx] = priority\n","\n","        # Update tree, by traversing along ancestors.\n","        # Continue until the root of the tree.\n","        while idx >= 2:\n","            # Get the index of the parent node\n","            idx //= 2\n","            # Value of the parent node is the sum of it's two children\n","            self.priority_sum[idx] = self.priority_sum[2 * idx] + self.priority_sum[2 * idx + 1]\n","\n","    def _sum(self):\n","        \"\"\"\n","        #### $\\sum_k p_k^\\alpha$\n","        \"\"\"\n","\n","        # The root node keeps the sum of all values\n","        return self.priority_sum[1]\n","\n","    def _min(self):\n","        \"\"\"\n","        #### $\\min_k p_k^\\alpha$\n","        \"\"\"\n","\n","        # The root node keeps the minimum of all values\n","        return self.priority_min[1]\n","\n","    def find_prefix_sum_idx(self, prefix_sum):\n","        \"\"\"\n","        #### Find largest $i$ such that $\\sum_{k=1}^{i} p_k^\\alpha  \\le P$\n","        \"\"\"\n","\n","        # Start from the root\n","        idx = 1\n","        while idx < self.capacity:\n","            # If the sum of the left branch is higher than required sum\n","            if self.priority_sum[idx * 2] > prefix_sum:\n","                # Go to left branch of the tree\n","                idx = 2 * idx\n","            else:\n","                # Otherwise go to right branch and reduce the sum of left\n","                #  branch from required sum\n","                prefix_sum -= self.priority_sum[idx * 2]\n","                idx = 2 * idx + 1\n","\n","        # We are at the leaf node. Subtract the capacity by the index in the tree\n","        # to get the index of actual value\n","        return idx - self.capacity\n","\n","    def sample(self, batch_size, beta):\n","        \"\"\"\n","        ### Sample from buffer\n","        \"\"\"\n","\n","        # Initialize samples\n","        samples = {\n","            'weights': np.zeros(shape=batch_size, dtype=np.float32),\n","            'indexes': np.zeros(shape=batch_size, dtype=np.int32),\n","        }\n","\n","        # Get sample indexes\n","        for i in range(batch_size):\n","            p = random.random() * self._sum()\n","            idx = self.find_prefix_sum_idx(p)\n","            samples['indexes'][i] = idx\n","\n","        # $\\min_i P(i) = \\frac{\\min_i p_i^\\alpha}{\\sum_k p_k^\\alpha}$\n","        prob_min = self._min() / self._sum()\n","        # $\\max_i w_i = \\bigg(\\frac{1}{N} \\frac{1}{\\min_i P(i)}\\bigg)^\\beta$\n","        max_weight = (prob_min * self.size) ** (-beta)\n","\n","        for i in range(batch_size):\n","            idx = samples['indexes'][i]\n","            # $P(i) = \\frac{p_i^\\alpha}{\\sum_k p_k^\\alpha}$\n","            prob = self.priority_sum[idx + self.capacity] / self._sum()\n","            # $w_i = \\bigg(\\frac{1}{N} \\frac{1}{P(i)}\\bigg)^\\beta$\n","            weight = (prob * self.size) ** (-beta)\n","            # Normalize by $\\frac{1}{\\max_i w_i}$,\n","            #  which also cancels off the $\\frac{1}{N}$ term\n","            samples['weights'][i] = weight / max_weight\n","\n","        # Get samples data\n","        samples['transitions'] = [self.data[idx] for idx in samples['indexes']]\n","\n","        return samples\n","\n","    def update_priorities(self, indexes, priorities):\n","        \"\"\"\n","        ### Update priorities\n","        \"\"\"\n","\n","        for idx, priority in zip(indexes, priorities):\n","            # Set current max priority\n","            self.max_priority = max(self.max_priority, priority)\n","\n","            # Calculate $p_i^\\alpha$\n","            priority_alpha = priority ** self.alpha\n","            # Update the trees\n","            self._set_priority_min(idx, priority_alpha)\n","            self._set_priority_sum(idx, priority_alpha)\n","\n","    def is_full(self):\n","        \"\"\"\n","        ### Whether the buffer is full\n","        \"\"\"\n","        return self.capacity == self.size"],"outputs":[],"metadata":{"id":"P24bHEJ_In9p"}},{"cell_type":"markdown","source":["# References\n","{% bibliography --cited %}"],"metadata":{}}]}
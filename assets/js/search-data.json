{
  
    
        "post0": {
            "title": "Prioritized Experience Replay",
            "content": "Experience Replay . Online Reinforcement Learning (RL) agents update their parameter as they make observation. | Two Issues: Strongly correlated updates (breaks i.i.d assumption of stochastic optimizers) | Rare events are immediately discarded | . | Experience Replay (ER) [Lin 1992] stores the observation in a replay memory Can mix recent and non-recent observations (no temporal correlation) | Rare event can be re-used | . | ER reduce amount of observations required to learn and replace with computational and memory resources (cheaper) | . Prioritized ER . The intuition behind prioritized experience replay [Schaul et al. 2015] is . Some transitions are more informative than other Transitions may be more or less surprising, redundant or task relevant | Some transition may not be immediately useful (RL agent not mature enough) | . | Replay important transitions more frequently and therefore learn more efficiently. | . Temporal Difference as proxy measurement . The magnitude of temporal difference (TD) error $ delta$ measures how far the value is from next-step bootstrap estimate [Andre et al. 1998]. | Reasonable proxy as it indicates how &quot;surprising&quot; the transition is. . Warning: Ignores inherent stochasticity in reward and transitions (poor TD estimates). . Warning: Limitation from partial observability (unlearnable transitions) | . Greedy TD-error prioritization . Algorithm Stores last TD error of a transtion in replay buffer | Transition with largest abs. TD error get replayed. Q-learning update $ propto$ TD-error | New transition gets highest priority | . | Substantial reduction in training effort | Implementation: Binary heap for priority queue Sampling: $O(1)$ | Update: $O(log N)$ | . | . Issues . To avoid expensive sweep over entire replay memory, only replayed transition is updated . Warning: Transition with low TD-error in first visit may not be replayed for a while. | Sensitive to noise (stochastic reward, bootstrapping noise) | Prone to over-fitting as high error transitions get replayed frequently (lack diversity) | . . Stochastic Prioritization . Interpolates between greedy and uniform random sampling | Probability of sampling transition $i$ is given by | . $$ P(i) = frac{p_i^ alpha}{ sum_k p_k^ alpha} $$ where, $p_i$ is the priority of transition | hyperparameter $ alpha$ determines how much prioritization to use (uniform sampling with $ alpha = 0$) | . | monotonic in transition priority | . Variants . Proportional prioritization: $p_i = | delta_i| + epsilon$ | Rank based prioritization: $p_i = frac{1}{rank(i)}$ where $rank(i)$ is rank of transition if sorted $| delta_i|$ insensitive to outlier and hence more robust | . | . Bias . Stochastic updates relies on the update being from same distribution as its expectation | Prioritized replay induce bias as it chages the update distribution | bias correction using importance sampling weights $$w_i = bigg( frac{1}{N} frac{1}{P(i)} bigg)^ beta$$ | where, hyper parameter $ beta$ fully compensates for non-uniform $P(i)$ when $ beta = 1$. | Normalize weights by $ frac{1}{ max_i w_i}$ for stability. | this is applied to Q-learning by $w_i delta_i$ (weighted IS) | . | Unbiased nature is most important towards the convergence at end of training. . Note: Process is highly non-stationary (changing policy, state dist. and bootstrapped targets) * Anneal the amount of correction over time. | prioritization ensures high-error transitions are seen many times while IS correction reduces gradient magnitude. | . . Implementation . Rank based prioritization . Approximate $cdf$ with piecewise linear function with $k$ equal size segments | First, sample a segment and then sample uniformly within among transitions within segment | for minibatch based learning: choose $k$ to be size of minibatch | sample one transition from each segment | . | . Propotional prioritization . Use sum tree | . Binary Segment Tree . Efficiently calculate $ sum_k^i p_k^ alpha$, the cumulative probability, which is needed to sample. | To find $ min p_i^ alpha$, which is needed for $ frac{1}{ max_i w_i}$. . Note: We can also use a min-heap for this. Binary Segment Tree lets us calculate these in $ mathcal{O}( log n)$ time, which is way more efficient that the naive $ mathcal{O}(n)$ approach. | . A Binary Segment Tree is a data structure that allows answering range queries over an array effectively, while still being flexible enough to allow modifying the array. . This is how a binary segment tree works for sum (it is similar for minimum) . Let $x_i$ where $i in {1, 2 cdots, N }$ be the list of $N$ values we want to represent. | Let $b_{h,j}$ be the $j^{ mathop{th}}$ node at height $h^{ mathop{th}}$ in the binary tree. | The two children of node $b_{h,j}$ are $b_{h+1,2j}$ and $b_{h+1,2j + 1}$. | The leaf nodes are at height $H = left lceil {1 + log_2 N} right rceil$ will have values of $x$. | . Every node keeps the sum of the two child nodes. That is, the root node keeps the sum of the entire array of values. The left and right children of the root node keep the sum of the first half of the array andthe sum of the second half of the array, respectively. and so on . $$b_{h,j} = sum_{k = (j -1) * 2^{H - h} + 1}^{j * 2^{H - h}} x_k$$ Number of nodes at height $h$, $$N_h = left lceil{ frac{N}{H - h + 1}} right rceil$$ This is equal to the sum of nodes in all levels above $h$. So we can use a single array $a$ to store the tree, where, $$b_{h,j} rightarrow a_{N_h + j}$$ . Then child nodes of $a_i$ are $a_{2i}$ and $a_{2i + 1}$. That is, $$a_i = a_{2i} + a_{2i + 1}$$ . This way of maintaining binary trees is very easy to program. . Note: indexing starting from 1. . Note: We use the same structure to compute the minimum. . import random import numpy as np from typing import List from dataclasses import dataclass @dataclass class Transition(): current_state = np.zeros(shape=(1, 10), dtype=np.float) action = 0 reward = 0.0 next_state = np.zeros(shape=(1, 10), dtype=np.float) done = 0 class PriorityExperienceReplayBuffer: def __init__(self, capacity, alpha): &quot;&quot;&quot; ### Initialize &quot;&quot;&quot; # We use a power of $2$ for capacity because it simplifies the code and debugging self.capacity = capacity # $ alpha$ self.alpha = alpha # Maintain segment binary trees to take sum and find minimum over a range self.priority_sum = [0 for _ in range(2 * self.capacity)] self.priority_min = [float(&#39;inf&#39;) for _ in range(2 * self.capacity)] # Current max priority, $p$, to be assigned to new transitions self.max_priority = 1. # Arrays for buffer self.data = [Transition() for _ in range(capacity)] # We use cyclic buffers to store data, and `next_idx` keeps the index of the next empty # slot self.next_idx = 0 # Size of the buffer self.size = 0 def add(self, transition: Transition): &quot;&quot;&quot; ### Add sample to queue &quot;&quot;&quot; # Get next available slot idx = self.next_idx # store in the queue self.data[idx] = transition # Increment next available slot self.next_idx = (idx + 1) % self.capacity # Calculate the size self.size = min(self.capacity, self.size + 1) # $p_i^ alpha$, new samples get `max_priority` priority_alpha = self.max_priority ** self.alpha # Update the two segment trees for sum and minimum self._set_priority_min(idx, priority_alpha) self._set_priority_sum(idx, priority_alpha) def _set_priority_min(self, idx, priority_alpha): &quot;&quot;&quot; #### Set priority in binary segment tree for minimum &quot;&quot;&quot; # Leaf of the binary tree idx += self.capacity self.priority_min[idx] = priority_alpha # Update tree, by traversing along ancestors. # Continue until the root of the tree. while idx &gt;= 2: # Get the index of the parent node idx //= 2 # Value of the parent node is the minimum of it&#39;s two children self.priority_min[idx] = min(self.priority_min[2 * idx], self.priority_min[2 * idx + 1]) def _set_priority_sum(self, idx, priority): &quot;&quot;&quot; #### Set priority in binary segment tree for sum &quot;&quot;&quot; # Leaf of the binary tree idx += self.capacity # Set the priority at the leaf self.priority_sum[idx] = priority # Update tree, by traversing along ancestors. # Continue until the root of the tree. while idx &gt;= 2: # Get the index of the parent node idx //= 2 # Value of the parent node is the sum of it&#39;s two children self.priority_sum[idx] = self.priority_sum[2 * idx] + self.priority_sum[2 * idx + 1] def _sum(self): &quot;&quot;&quot; #### $ sum_k p_k^ alpha$ &quot;&quot;&quot; # The root node keeps the sum of all values return self.priority_sum[1] def _min(self): &quot;&quot;&quot; #### $ min_k p_k^ alpha$ &quot;&quot;&quot; # The root node keeps the minimum of all values return self.priority_min[1] def find_prefix_sum_idx(self, prefix_sum): &quot;&quot;&quot; #### Find largest $i$ such that $ sum_{k=1}^{i} p_k^ alpha le P$ &quot;&quot;&quot; # Start from the root idx = 1 while idx &lt; self.capacity: # If the sum of the left branch is higher than required sum if self.priority_sum[idx * 2] &gt; prefix_sum: # Go to left branch of the tree idx = 2 * idx else: # Otherwise go to right branch and reduce the sum of left # branch from required sum prefix_sum -= self.priority_sum[idx * 2] idx = 2 * idx + 1 # We are at the leaf node. Subtract the capacity by the index in the tree # to get the index of actual value return idx - self.capacity def sample(self, batch_size, beta): &quot;&quot;&quot; ### Sample from buffer &quot;&quot;&quot; # Initialize samples samples = { &#39;weights&#39;: np.zeros(shape=batch_size, dtype=np.float32), &#39;indexes&#39;: np.zeros(shape=batch_size, dtype=np.int32), } # Get sample indexes for i in range(batch_size): p = random.random() * self._sum() idx = self.find_prefix_sum_idx(p) samples[&#39;indexes&#39;][i] = idx # $ min_i P(i) = frac{ min_i p_i^ alpha}{ sum_k p_k^ alpha}$ prob_min = self._min() / self._sum() # $ max_i w_i = bigg( frac{1}{N} frac{1}{ min_i P(i)} bigg)^ beta$ max_weight = (prob_min * self.size) ** (-beta) for i in range(batch_size): idx = samples[&#39;indexes&#39;][i] # $P(i) = frac{p_i^ alpha}{ sum_k p_k^ alpha}$ prob = self.priority_sum[idx + self.capacity] / self._sum() # $w_i = bigg( frac{1}{N} frac{1}{P(i)} bigg)^ beta$ weight = (prob * self.size) ** (-beta) # Normalize by $ frac{1}{ max_i w_i}$, # which also cancels off the $ frac{1}{N}$ term samples[&#39;weights&#39;][i] = weight / max_weight # Get samples data samples[&#39;transitions&#39;] = [self.data[idx] for idx in samples[&#39;indexes&#39;]] return samples def update_priorities(self, indexes, priorities): &quot;&quot;&quot; ### Update priorities &quot;&quot;&quot; for idx, priority in zip(indexes, priorities): # Set current max priority self.max_priority = max(self.max_priority, priority) # Calculate $p_i^ alpha$ priority_alpha = priority ** self.alpha # Update the trees self._set_priority_min(idx, priority_alpha) self._set_priority_sum(idx, priority_alpha) def is_full(self): &quot;&quot;&quot; ### Whether the buffer is full &quot;&quot;&quot; return self.capacity == self.size . References . Lin, L.-J.I. 1992. Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine Learning, 293–321. | Schaul, T., Quan, J., Antonoglou, I., and Silver, D. 2015. Prioritized Experience Replay. http://arxiv.org/abs/1511.05952. | Andre, D., Friedman, N., and Parr, R. 1998. Generalized Prioritized Sweeping. Advances in Neural Information Processing Systems, MIT Press. | .",
            "url": "https://agupta83.github.io/annotated_notes/rl/2021/07/21/Prioritized-Experience-Replay.html",
            "relUrl": "/rl/2021/07/21/Prioritized-Experience-Replay.html",
            "date": " • Jul 21, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Citation example [Wikipedia contributors 2021] . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ . References . Wikipedia contributors. 2021. Maximum subarray problem — Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/Maximum_subarray_problem. | .",
            "url": "https://agupta83.github.io/annotated_notes/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://agupta83.github.io/annotated_notes/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://agupta83.github.io/annotated_notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://agupta83.github.io/annotated_notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}